# Python Version: 3.10.11

# --- Backend Framework & Server ---
# fastapi==0.110.0
# uvicorn[standard]==0.29.0
# pydantic<2.0.0  # Added explicit constraint for FastAPI compatibility

# # --- Task Queue ---
# # celery==5.3.6
# # redis==5.0.3

# # --- Video & Audio Processing ---
# moviepy==1.0.3
# ffmpeg-python==0.2.0
# openai-whisper==20231117
# pyannote.audio==3.1.1

# --- ML Core & Embeddings ---
# IMPORTANT: PyTorch, TorchVision, and TorchAudio are installed separately in Step 2.
# See project documentation for OS-specific PyTorch installation instructions.
# Target versions:
# torch~=2.1.0
# torchaudio~=2.1.0
# torchvision~=0.16.0

# Ensure compatible protobuf version for open_clip_torch
# protobuf>=3.20.2,<4.0.0  # Added explicit constraint
# open_clip_torch==2.20.0

# Transformers and related libraries
# transformers==4.38.2  # Compatible with sentence-transformers
# sentence-transformers==2.7.0
# audiocraft>=1.3.0  # Requires Python 3.9+ and PyTorch 2.1.0
# accelerate==0.27.2

# --- Vector DB ---
# chromadb==0.4.24
# faiss-cpu==1.7.4 # Optional, uncomment if using FAISS

# --- LLM / RAG / Agents ---
# Adjusted for compatibility
# langchain
# langchain-community
# langchain-core
# langchain-huggingface
# langgraph
# ollama==0.1.8

# --- Monitoring ---
# langsmith

# --- Utilities ---
# python-dotenv==1.0.1
# numpy==1.26.4
# scipy==1.12.0
# requests==2.31.0
# psycopg2-binary==2.9.9 # If using PostgreSQL
# Pillow==10.2.0
# uuid # Standard library

# ClipPilot.ai - Backend Python Dependencies
# For macOS (and generally cross-platform, with notes)

# --- Core Framework & API ---
fastapi
uvicorn[standard] # Includes common optional dependencies for uvicorn

# --- Database Connector (PostgreSQL) ---
psycopg2-binary # For connecting to PostgreSQL

# --- Task Queueing ---
celery
redis # Python client for Redis

# --- Utilities ---
python-dotenv # For managing .env files

# --- Video & Audio Processing ---
moviepy
ffmpeg-python # Note: Requires the ffmpeg binary to be installed on your system (e.g., via `brew install ffmpeg`)

# --- Speech Recognition & Diarization ---
# For Whisper, the official package is openai-whisper
openai-whisper
pyannote.audio # This can be a heavy install. Ensure you have PyTorch installed first.

# --- ML/AI - Embeddings, LLMs, Transformers ---
torch # For PyTorch. On Apple Silicon (M1/M2/M3), this should pick up MPS support if available.
torchvision # Usually installed alongside torch
torchaudio # Often useful with torch for audio tasks, and sometimes a pyannote dependency
sentence-transformers
open_clip_torch
chromadb # Or 'faiss-cpu' if you decide to switch to FAISS
transformers # For Hugging Face models (Llama2, Gemma, MusicGen components)

# --- LangChain ---
langchain
langchain-community # For integrations like Ollama
langgraph

# --- Audio Generation ---
# MusicGen is often part of Facebook Research's 'audiocraft' library
# audiocraft # Main library for MusicGen

# --- Optional for MLOps (if interacting via Python SDKs) ---
# langsmith # If you plan to use the LangSmith Python SDK directly
# opentelemetry-api
# opentelemetry-sdk
# opentelemetry-exporter-otlp
# opentelemetry-instrumentation-fastapi
# opentelemetry-instrumentation-celery

# --- How to use ---
# 1. Ensure you have Python 3.8+ installed.
# 2. Create and activate a virtual environment:
#    python3 -m venv venv
#    source venv/bin/activate
# 3. Install dependencies:
#    pip install -r requirements.txt
# 4. For Apple Silicon (M1/M2/M3) Macs, verify PyTorch MPS support after installation if needed for performance.
# 5. Remember to install system-level dependencies like ffmpeg:
#    brew install ffmpeg
# 6. Ensure PostgreSQL server is running and accessible if using it.